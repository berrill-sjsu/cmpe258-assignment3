{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dISEXCVNaFu"
      },
      "source": [
        "# Timothy Berrilll  \n",
        "## CMPE 258 Assignment 3  \n",
        "## Question 1  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QDnmmQtNpyh"
      },
      "source": [
        "### Section 0 - Setting up Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC7PJKpoNxqI"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjiylTxlNlbg"
      },
      "source": [
        "### Section 1 - Creating the real-estate data\n",
        "The data should have 10M samples, with 25 features. The label will be the value of the home."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws-Hsl60NED1"
      },
      "source": [
        "# choose random np seed\n",
        "np.random.seed(0)\n",
        "\n",
        "# global values for the number of features and samples\n",
        "NUM_FEATURES = 25\n",
        "NUM_SAMPLES = 10000000\n",
        "\n",
        "# create random features shaped 25 x 10M\n",
        "features = np.random.randn(NUM_FEATURES * NUM_SAMPLES)\n",
        "features = features.reshape(NUM_SAMPLES, NUM_FEATURES)\n",
        "\n",
        "# create random labels for the home prices\n",
        "labels = np.random.randint(low=75000, high=12000000, size=(NUM_SAMPLES, 1))\n",
        "\n",
        "# normalize the output data between 0 and 1\n",
        "labels = (labels - np.min(labels)) / np.max(labels)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXVHXgoyPBV6"
      },
      "source": [
        "# split up into 90 / 10 train split\n",
        "x_train, x_test, y_train, y_test = train_test_split(features, labels, train_size=0.9, random_state=0)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8jl9uxbQnMP",
        "outputId": "1ab6d65e-9f04-469e-9c37-d5830c89c103"
      },
      "source": [
        "# print out the shapes to make sure they look right\n",
        "print(f'X train shape: {x_train.shape}')\n",
        "print(f'X test  shape: {x_test.shape}')\n",
        "print(f'Y train shape: {y_train.shape}')\n",
        "print(f'Y test  shape: {y_test.shape}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X train shape: (9000000, 25)\n",
            "X test  shape: (1000000, 25)\n",
            "Y train shape: (9000000, 1)\n",
            "Y test  shape: (1000000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1Fajv3IReJ9"
      },
      "source": [
        "### Section 2 - Create a Model\n",
        "Create a 3 layer densely connected model. Has to have at least one type of regularization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZlqCMAbRb2K"
      },
      "source": [
        "def get_dense_model(input_shape):\n",
        "  \"\"\"\n",
        "  Makes a 3 layer densly connected model\n",
        "  :param input_shape: the input shape to the model\n",
        "  :return: tf.keras.models.Model object\n",
        "  \"\"\"\n",
        "  # define model input shape\n",
        "  input = tf.keras.Input(shape=input_shape, name='model_input')\n",
        "  x = input\n",
        "\n",
        "  # use functional API to define dense model\n",
        "  x = tf.keras.layers.Dense(32,  activation='relu')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Dense(64,  activation='relu')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  output = tf.keras.layers.Dense(1, activation='relu')(x)\n",
        "\n",
        "  # create model object and return \n",
        "  return tf.keras.models.Model(inputs=[input], outputs=[output])\n",
        "\n",
        "dense_model = get_dense_model(input_shape=(NUM_FEATURES))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQXlP1DVS45R"
      },
      "source": [
        "### Section 3 - Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cks7oa3ES3Zw"
      },
      "source": [
        "# define constants used for training\n",
        "EPOCHS = 1000\n",
        "BATCH_SIZE = 4096"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0ccL5_qTL_F"
      },
      "source": [
        "dense_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse', 'mae'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16Zf4izwTYln",
        "outputId": "9467f846-6f53-4140-bfba-5eb12cd5bded"
      },
      "source": [
        "# the following line would be used if you actually wanted to train for 1000 epochs\n",
        "# I obviously dont want to do this because it would take forever and the training data\n",
        "# is just made up anyway so it wouldn't really learn anything useful\n",
        "# dense_model.fit(x=x_train, y=y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=True)\n",
        "\n",
        "# instead, this fit call only trains for 2 epochs. But it would work for 1000\n",
        "dense_model.fit(x=x_train, y=y_train, batch_size=BATCH_SIZE, epochs=2, verbose=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "2198/2198 [==============================] - 17s 7ms/step - loss: 0.0823 - mse: 0.0823 - mae: 0.2485\n",
            "Epoch 2/2\n",
            "2198/2198 [==============================] - 15s 7ms/step - loss: 0.0823 - mse: 0.0823 - mae: 0.2485\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1ce0107a50>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Me5x5MbVTmLe",
        "outputId": "6060e6cb-5e42-432e-8827-ea55059acd89"
      },
      "source": [
        "loss, mse, mae = dense_model.evaluate(x=x_test, y=y_test, batch_size=BATCH_SIZE)\n",
        "print(f'MSE: {mse}')\n",
        "print(f'MAE: {mae}')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0822 - mse: 0.0822 - mae: 0.2483\n",
            "MSE: 0.08221711963415146\n",
            "MAE: 0.24828332662582397\n"
          ]
        }
      ]
    }
  ]
}